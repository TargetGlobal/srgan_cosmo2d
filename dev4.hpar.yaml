Defaults:
  # note, CFS-based location will run slower vs. SCRATCH
  cfs_out: &CFS_OUT  /global/homes/b/balewski/prje/tmp_NyxHydro4kE/
  cfs_data: &CFS_DATA  /global/homes/b/balewski/prje/data_NyxHydro4k/B/
  summit_data: &AST153_PROJ  /gpfs/alpine/ast153/proj-shared/balewski/superRes-packed_h5/
  summit_out: &AST153_WORLD /gpfs/alpine/world-shared/ast153/balewski/tmp_NyxHydro4kD/


facility_conf:
  perlmutter:
    base_path:  *CFS_OUT
    data_path:  /pscratch/sd/b/balewski/superRes-packed_h5/  
    G_LR: {decay/epochs: 1000, gamma: 0.4, init: 6.e-5}	
    D_LR: {decay/epochs: 1000, gamma: 0.4, init: 4.e-5 }
    batch_size: 16   #for A100
    D_num_fc_layer: 5 # is large for A100
    
  summit:
    D_num_fc_layer: 3 # is small for V100	
    batch_size: 6

Xbase_path:   # obsolete
  corigpu:  /global/cscratch1/sd/balewski/tmp_digitalMind/superRes-cgpu/august/  
  summitlogin: *AST153_WORLD
    
Xdata_path:   # obsolete
  #corigpu: /global/cfs/cdirs/m3363/balewski/superRes-packed_h5/
  corigpu:  *CFS_DATA
  #perlmutter: *CFS_DATA
  summit: *AST153_PROJ
  summitlogin: *AST153_PROJ

myId: dev4-dual

# optional, reduces training samples
#max_glob_samples_per_epoch: 256  # do 1400 or 256
hr_size: 512
upscale_factor: 4
num_inp_chan: 1  # grey images
#jnum_inp_chan=3  # RGB images

comment: production config for Super-Resolution
const_local_batch: true

model_conf:
  comment: D+G models taken from  Lornatang Liu Changyu, https://github.com/Lornatang/SRGAN-PyTorch
  tb_model_graph: null # D,G, or null
  D:
    fc_layers: null
    print_summary: 0  # 0=off, 1=layers, 2=torchsummary, 3=both
  G:
    print_summary: 0  # see D for explanation
    is_empty: null


num_cpu_workers: 4
opt_pytorch: {autotune: true, detect_anomaly: false, zerograd: true}

text_log_interval/epochs: 2
checkpoint_interval/epochs: 50
pred_dump_interval/epochs: 100  # 0=OFF 

train_conf:
  adv_warmup_epochs: 1
  PG_LR: { init: 1.e-4}	

  # Train epochs.
  pre_epochs:   5   #  generator training phase.
  epochs:       10   #  adversarial training phase.

  # Perceptual G-loss function weights:
  pixel_weight: 0.8
  content_weight: 0.2
  advers_weight: 0.03
  fft_weight: 0.04
  
  # legacy variables
  start_pre_epoch: 0
  start_epoch:            0    # ???The number of initial iterations of the adversarial training phase. When set to 0, it means incremental training.
  resume:        False  # Set to `True` to continue training from checkpoint
  resume_p_weight:     ""    # Restore the weight of the generator model during generator training.
  resume_d_weight:        ""  
  resume_g_weight:        ""   
